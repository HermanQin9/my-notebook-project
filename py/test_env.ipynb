{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6900ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    # Import the pipeline execution function (assumes pipeline.py defines run_pipeline)\n",
    "    from pipeline import run_pipeline\n",
    "except ImportError:\n",
    "    # If pipeline is a module in the same package\n",
    "    from .pipeline import run_pipeline\n",
    "\n",
    "class PipelineEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A custom Gym environment for optimizing a machine learning pipeline using RL.\n",
    "    The action space is hierarchical (node, method, hyperparams), and the state \n",
    "    includes pipeline context, performance metrics, and budget info.\n",
    "    \"\"\"\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "    \n",
    "    def __init__(self, pipeline_nodes=None, total_budget=100.0, max_steps=50, \n",
    "                 cost_penalty=0.0, include_stats=False):\n",
    "        \"\"\"\n",
    "        Initialize the PipelineEnv.\n",
    "        \n",
    "        Parameters:\n",
    "            pipeline_nodes (list or None): Sequence of node identifiers to include in the pipeline.\n",
    "                                           If None, use the default full pipeline node list.\n",
    "            total_budget (float): Total allowable cost (e.g. time budget) for an episode.\n",
    "            max_steps (int): Maximum number of steps (actions) per episode.\n",
    "            cost_penalty (float): Lambda coefficient for cost in the reward function.\n",
    "            include_stats (bool): If True, include historical statistics (e.g. method usage counts) in state.\n",
    "        \"\"\"\n",
    "        super(PipelineEnv, self).__init__()\n",
    "        \n",
    "        # Define the pipeline node list and methods for each node.\n",
    "        # If pipeline_nodes is not provided, use a default sequence of nodes.\n",
    "        if pipeline_nodes is None:\n",
    "            self.pipeline_nodes = ['N0','N1','N2','N3','N4','N5']  # default full pipeline\n",
    "        else:\n",
    "            self.pipeline_nodes = pipeline_nodes\n",
    "        self.num_nodes = len(self.pipeline_nodes)\n",
    "        \n",
    "        # Define available methods for each node (this should align with pipeline.py capabilities).\n",
    "        # For each node, list the valid methods. Methods are identified by name strings.\n",
    "        self.methods_for_node = {\n",
    "            'N0': ['api'],\n",
    "            'N1': ['mean', 'knn', 'median'],\n",
    "            'N2': ['default'],\n",
    "            'N3': ['none', 'variance'],\n",
    "            'N4': ['std', 'robust'],\n",
    "            'N5': ['rf', 'gbr']\n",
    "        }\n",
    "        # Filter methods_for_node to only include nodes in pipeline_nodes:\n",
    "        self.methods_for_node = {node: self.methods_for_node[node] for node in self.pipeline_nodes if node in self.methods_for_node}\n",
    "        \n",
    "        # Create a global index mapping for nodes and methods (for use in spaces and state).\n",
    "        self.node_index = {node: idx for idx, node in enumerate(self.pipeline_nodes)}\n",
    "        # We'll use a fixed maximum number of methods for action space. Determine the max length:\n",
    "        self.max_methods = max(len(methods) for methods in self.methods_for_node.values()) if self.methods_for_node else 0\n",
    "        # Define a global method index mapping per node for convenience (not strictly needed globally).\n",
    "        # (For simplicity, method selection in the action will be interpreted relative to the chosen node's list.)\n",
    "        \n",
    "        # Define hyperparameter vector dimension (d): choose a unified length that covers max needed parameters.\n",
    "        # Based on known pipeline, max hyperparameters for any method ~ 2 (e.g., Random Forest has n_estimators & max_depth).\n",
    "        self.hyperparam_dim = 2  # we use 2 as a default; this can be adjusted if methods with more params are added.\n",
    "        \n",
    "        # Gym action space: Tuple( node_selection, method_selection, hyperparam_vector ).\n",
    "        self.action_space = spaces.Tuple((\n",
    "            spaces.Discrete(self.num_nodes),                 # Node index\n",
    "            spaces.Discrete(self.max_methods),               # Method index (to be interpreted according to node)\n",
    "            spaces.Box(low=0.0, high=1.0, shape=(self.hyperparam_dim,), dtype=np.float32)  # Hyperparameter vector\n",
    "        ))\n",
    "        \n",
    "        # Gym observation space: use a Dict for structured state.\n",
    "        obs_spaces = {\n",
    "            \"step\": spaces.Box(low=0, high=max_steps, shape=(1,), dtype=np.int32),\n",
    "            \"remaining_budget\": spaces.Box(low=0.0, high=total_budget, shape=(1,), dtype=np.float32),\n",
    "            \"last_node\": spaces.Discrete(self.num_nodes),    # index of last selected node\n",
    "            \"last_method\": spaces.Discrete(self.max_methods),# index of last selected method (relative to node's list)\n",
    "            \"last_hyperparams\": spaces.Box(low=0.0, high=1.0, shape=(self.hyperparam_dim,), dtype=np.float32),\n",
    "            \"node_selected\": spaces.MultiBinary(self.num_nodes),  # binary flags for whether each node has been selected\n",
    "            \"val_mae\": spaces.Box(low=0.0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            \"val_r2\": spaces.Box(low=-np.inf, high=1.0, shape=(1,), dtype=np.float32),\n",
    "            \"last_runtime\": spaces.Box(low=0.0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            \"current_n_features\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.int32)\n",
    "        }\n",
    "        # Include optional historical stats if requested (e.g., method usage counts).\n",
    "        self.include_stats = include_stats\n",
    "        if include_stats:\n",
    "            # Prepare a vector for method usage counts (for all methods across all nodes).\n",
    "            # We will order this vector as [count(node0_method0), count(node0_method1), ..., count(node1_method0), ...].\n",
    "            total_method_options = 0\n",
    "            self.method_index_offset = {}  # keep track of index offset for each node in the vector\n",
    "            for node in self.pipeline_nodes:\n",
    "                self.method_index_offset[node] = total_method_options\n",
    "                total_method_options += len(self.methods_for_node.get(node, []))\n",
    "            obs_spaces[\"method_counts\"] = spaces.Box(low=0, high=max_steps, shape=(total_method_options,), dtype=np.int32)\n",
    "        \n",
    "        self.observation_space = spaces.Dict(obs_spaces)\n",
    "        \n",
    "        # Save configuration parameters\n",
    "        self.total_budget = total_budget\n",
    "        self.max_steps = max_steps\n",
    "        self.cost_penalty = cost_penalty\n",
    "        \n",
    "        # Initialize dynamic variables\n",
    "        self.step_count = 0\n",
    "        self.remaining_budget = None\n",
    "        self.pipeline_config = None    # will hold current pipeline configuration (dict of nodes to {method, params})\n",
    "        self.last_action = None        # store last action (node, method, hyperparams) for reference\n",
    "        self.best_val_mae = None\n",
    "        self.no_improve_steps = None\n",
    "        \n",
    "        # Reset environment to initial state\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment to an initial state at the start of an episode.\"\"\"\n",
    "        # Reset counters and budget\n",
    "        self.step_count = 0\n",
    "        self.remaining_budget = float(self.total_budget)\n",
    "        self.no_improve_steps = 0\n",
    "        self.best_val_mae = float('inf')\n",
    "        # Initialize pipeline configuration to default methods (or a provided baseline).\n",
    "        # Here we pick the first method of each node's list as a default (could also be a specific known good default).\n",
    "        self.pipeline_config = {}\n",
    "        for node in self.pipeline_nodes:\n",
    "            methods = self.methods_for_node.get(node, [])\n",
    "            if len(methods) > 0:\n",
    "                default_method = methods[0]\n",
    "            else:\n",
    "                default_method = None\n",
    "            # No hyperparameters initially (or a default hyperparam config if needed).\n",
    "            self.pipeline_config[node] = {\n",
    "                \"method\": default_method,\n",
    "                \"params\": {}  # will fill when method actually requires it\n",
    "            }\n",
    "        # Run the pipeline once to get initial performance metrics (if needed to start state).\n",
    "        initial_val_mae = 0.0\n",
    "        initial_val_r2 = 0.0\n",
    "        initial_runtime = 0.0\n",
    "        if self.pipeline_config:\n",
    "            # If pipeline can run with default config, do so to get initial metrics.\n",
    "            try:\n",
    "                result = run_pipeline(self.pipeline_config, return_intermediates=True)\n",
    "            except Exception as e:\n",
    "                # If pipeline execution fails (e.g. due to missing data), handle gracefully.\n",
    "                print(\"Warning: run_pipeline failed during reset:\", e)\n",
    "                result = None\n",
    "            if result is not None:\n",
    "                # Assume result may be a tuple: (metrics, intermediates) or just metrics.\n",
    "                if isinstance(result, tuple):\n",
    "                    metrics, intermediates = result\n",
    "                else:\n",
    "                    metrics, intermediates = result, None\n",
    "                # Extract metrics if available\n",
    "                if isinstance(metrics, dict):\n",
    "                    initial_val_mae = metrics.get(\"val_mae\", 0.0)\n",
    "                    initial_val_r2 = metrics.get(\"val_r2\", 0.0)\n",
    "                # If intermediates available, perhaps get feature count from final data\n",
    "                # (This assumes intermediates[-1] contains final dataset or model input)\n",
    "                if intermediates:\n",
    "                    try:\n",
    "                        # If the last intermediate has features, get its shape\n",
    "                        final_data = intermediates[-1].get(\"data\") if isinstance(intermediates[-1], dict) else intermediates[-1]\n",
    "                        if hasattr(final_data, \"shape\"):\n",
    "                            # final_data could be (X_val, y_val) tuple or similar; handle accordingly\n",
    "                            if isinstance(final_data, tuple):\n",
    "                                X_val = final_data[0]\n",
    "                                current_n_features = X_val.shape[1] if hasattr(X_val, \"shape\") else 0\n",
    "                            else:\n",
    "                                current_n_features = final_data.shape[1] if len(final_data.shape) > 1 else final_data.shape[0]\n",
    "                        else:\n",
    "                            current_n_features = 0\n",
    "                    except Exception:\n",
    "                        current_n_features = 0\n",
    "                else:\n",
    "                    current_n_features = 0\n",
    "            else:\n",
    "                # If no result, keep initial metrics zero (or could set to None)\n",
    "                current_n_features = 0\n",
    "        else:\n",
    "            # No pipeline nodes? then nothing to run\n",
    "            current_n_features = 0\n",
    "        \n",
    "        # Initialize last action info as none (or default no-op)\n",
    "        self.last_action = (-1, -1, np.zeros(self.hyperparam_dim, dtype=np.float32))\n",
    "        # Initialize node_selected flags\n",
    "        node_flags = np.zeros(self.num_nodes, dtype=int)\n",
    "        # Initialize method_counts if applicable\n",
    "        if self.include_stats:\n",
    "            total_method_options = list(self.method_index_offset.values())[-1] + len(self.methods_for_node.get(self.pipeline_nodes[-1], [])) if self.method_index_offset else 0\n",
    "            method_counts = np.zeros(total_method_options, dtype=int)\n",
    "            # Mark initial default methods as used once (if we consider initial config as a \"use\")\n",
    "            # Here, we won't count initial defaults as agent's choices, so keep at zero.\n",
    "        else:\n",
    "            method_counts = None\n",
    "        \n",
    "        # Construct the initial observation dictionary\n",
    "        obs = {\n",
    "            \"step\": np.array([self.step_count], dtype=np.int32),\n",
    "            \"remaining_budget\": np.array([self.remaining_budget], dtype=np.float32),\n",
    "            \"last_node\": np.array([self.node_index.get(self.pipeline_nodes[0], 0)], dtype=np.int32),  # e.g., start at first node by default\n",
    "            \"last_method\": np.array([0], dtype=np.int32),  # default index 0 method for that node\n",
    "            \"last_hyperparams\": np.zeros((self.hyperparam_dim,), dtype=np.float32),\n",
    "            \"node_selected\": node_flags.astype(np.int8),\n",
    "            \"val_mae\": np.array([initial_val_mae], dtype=np.float32),\n",
    "            \"val_r2\": np.array([initial_val_r2], dtype=np.float32),\n",
    "            \"last_runtime\": np.array([initial_runtime], dtype=np.float32),\n",
    "            \"current_n_features\": np.array([current_n_features], dtype=np.int32)\n",
    "        }\n",
    "        if self.include_stats:\n",
    "            obs[\"method_counts\"] = method_counts.astype(np.int32)\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute one step in the environment with the given action.\n",
    "        Action is a tuple: (node_index, method_index, hyperparam_vector).\n",
    "        \"\"\"\n",
    "        # Unpack action tuple\n",
    "        node_idx, method_idx, hyper_vector = action\n",
    "        # Ensure hyper_vector is a numpy array for ease of handling\n",
    "        hyper_vector = np.array(hyper_vector, dtype=np.float32)\n",
    "        \n",
    "        # Initialize reward\n",
    "        reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        \n",
    "        # Map the node index to actual node identifier\n",
    "        if node_idx < 0 or node_idx >= self.num_nodes:\n",
    "            # Invalid node selection\n",
    "            reward = -100.0  # heavy penalty for illegal action\n",
    "            terminated = False\n",
    "            truncated = True\n",
    "            info[\"error\"] = \"Invalid node selected\"\n",
    "            # Return current state (unchanged) with penalty\n",
    "            return self._get_obs(), reward, terminated, truncated, info\n",
    "        node = self.pipeline_nodes[node_idx]\n",
    "        \n",
    "        # Map the method index to actual method name for the chosen node\n",
    "        methods = self.methods_for_node.get(node, [])\n",
    "        if method_idx < 0 or method_idx >= len(methods):\n",
    "            # Invalid method for this node\n",
    "            reward = -100.0\n",
    "            terminated = False\n",
    "            truncated = True\n",
    "            info[\"error\"] = f\"Invalid method selected for node {node}\"\n",
    "            return self._get_obs(), reward, terminated, truncated, info\n",
    "        method = methods[method_idx]\n",
    "        \n",
    "        # Map hyperparameter vector [0,1]^d to actual hyperparameter values for this method\n",
    "        params = self._map_hyperparams(node, method, hyper_vector)\n",
    "        \n",
    "        # Update the pipeline configuration with the chosen method and params for the node\n",
    "        self.pipeline_config[node] = {\"method\": method, \"params\": params}\n",
    "        \n",
    "        # Mark this node as selected (for observation)\n",
    "        # (We consider that the node is now configured/visited; this can be used to avoid re-selecting if not desired)\n",
    "        # But we do not forbid revisiting in logic; we only mark for state info.\n",
    "        \n",
    "        # Run the pipeline with the new configuration to get performance metrics and cost\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            result = run_pipeline(self.pipeline_config, return_intermediates=True)\n",
    "        except Exception as e:\n",
    "            # If pipeline execution fails, terminate episode\n",
    "            reward = -100.0\n",
    "            terminated = False\n",
    "            truncated = True\n",
    "            info[\"error\"] = f\"Pipeline execution failed: {e}\"\n",
    "            return self._get_obs(), reward, terminated, truncated, info\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calculate runtime cost for this step\n",
    "        step_runtime = end_time - start_time\n",
    "        cost = step_runtime\n",
    "        # If the pipeline result provides more precise cost info, use it (e.g., per node times)\n",
    "        metrics = {}\n",
    "        intermediates = None\n",
    "        if result is not None:\n",
    "            if isinstance(result, tuple):\n",
    "                metrics, intermediates = result\n",
    "            else:\n",
    "                metrics = result\n",
    "            # If the pipeline returns an info dict with cost for this node, use that instead of total time\n",
    "            if isinstance(metrics, dict) and \"cost\" in metrics:\n",
    "                # 'cost' could be total or per-node; here assume total cost\n",
    "                cost = metrics[\"cost\"]\n",
    "            # Alternatively, if intermediates provide time per node:\n",
    "            if intermediates and isinstance(intermediates, list):\n",
    "                # If each intermediate has a time or cost, we could extract the cost for this node.\n",
    "                # This is placeholder logic; actual implementation depends on pipeline details.\n",
    "                for interm in intermediates:\n",
    "                    if isinstance(interm, dict) and \"node\" in interm and interm.get(\"node\") == node and \"time\" in interm:\n",
    "                        cost = interm[\"time\"]\n",
    "                        break\n",
    "        \n",
    "        # Update remaining budget\n",
    "        self.remaining_budget -= cost\n",
    "        \n",
    "        # Extract performance metrics from the result (val_mae, val_r2)\n",
    "        val_mae = 0.0\n",
    "        val_r2 = 0.0\n",
    "        if isinstance(metrics, dict):\n",
    "            val_mae = metrics.get(\"val_mae\", 0.0)\n",
    "            val_r2 = metrics.get(\"val_r2\", 0.0)\n",
    "        \n",
    "        # Compute reward: negative val_mae minus lambda * cost\n",
    "        reward = -val_mae - self.cost_penalty * cost\n",
    "        \n",
    "        # Update improvement tracking for convergence\n",
    "        if val_mae + 1e-9 < self.best_val_mae - 0.01:\n",
    "            # Significant improvement (more than 0.01)\n",
    "            self.best_val_mae = val_mae\n",
    "            self.no_improve_steps = 0\n",
    "        else:\n",
    "            self.no_improve_steps += 1\n",
    "        \n",
    "        # Determine termination conditions\n",
    "        if self.no_improve_steps >= 10:\n",
    "            # No significant improvement for 10 steps -> convergence reached\n",
    "            terminated = True\n",
    "            info[\"reason\"] = \"converged_no_improvement\"\n",
    "        if self.remaining_budget < 0.0:\n",
    "            # Budget exceeded\n",
    "            reward = -100.0  # heavy penalty for overshooting budget\n",
    "            truncated = True\n",
    "            terminated = False\n",
    "            info[\"error\"] = \"budget_exceeded\"\n",
    "        elif self.remaining_budget == 0.0:\n",
    "            # Budget exactly exhausted -> end episode (not an error, considered normal termination)\n",
    "            terminated = True\n",
    "            info[\"reason\"] = \"budget_exhausted\"\n",
    "        if self.step_count + 1 >= self.max_steps:\n",
    "            # Reached max steps limit\n",
    "            truncated = True\n",
    "            info[\"reason\"] = \"max_steps_reached\"\n",
    "        \n",
    "        # Update step count\n",
    "        self.step_count += 1\n",
    "        \n",
    "        # Prepare next state observation\n",
    "        obs = self._get_obs(last_node=node_idx, last_method=method_idx, last_hyperparams=hyper_vector,\n",
    "                            val_mae=val_mae, val_r2=val_r2, runtime=cost, intermediates=intermediates)\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def _get_obs(self, last_node=None, last_method=None, last_hyperparams=None, \n",
    "                 val_mae=0.0, val_r2=0.0, runtime=0.0, intermediates=None):\n",
    "        \"\"\"\n",
    "        Construct the observation dictionary based on current environment state.\n",
    "        This internal helper is used in reset() and step() to avoid code duplication.\n",
    "        \"\"\"\n",
    "        if last_node is None or last_method is None or last_hyperparams is None:\n",
    "            # If not provided, use the stored last action (after reset or in case of invalid action)\n",
    "            last_node = -1 if self.last_action is None else self.last_action[0]\n",
    "            last_method = -1 if self.last_action is None else self.last_action[1]\n",
    "            last_hyperparams = np.zeros(self.hyperparam_dim, dtype=np.float32) if self.last_action is None else self.last_action[2]\n",
    "        # Update last action memory\n",
    "        self.last_action = (last_node, last_method, np.array(last_hyperparams, dtype=np.float32))\n",
    "        \n",
    "        # Determine current number of features from intermediates if available\n",
    "        current_n_features = 0\n",
    "        if intermediates:\n",
    "            try:\n",
    "                # If the intermediates include the dataset after the last modified node\n",
    "                # Find data shape from intermediates (assuming list of dicts with maybe 'data' or similar)\n",
    "                final_data = None\n",
    "                if isinstance(intermediates, list):\n",
    "                    # If we have a list of intermediate outputs for each node in sequence\n",
    "                    final_data = intermediates[-1]\n",
    "                elif isinstance(intermediates, dict):\n",
    "                    # If intermediates is a dict of node outputs\n",
    "                    final_data = intermediates.get(last_node)\n",
    "                # Try to get number of features from final_data\n",
    "                if final_data is not None:\n",
    "                    if isinstance(final_data, tuple):\n",
    "                        # If final_data is (X_val, y_val) tuple\n",
    "                        X_val = final_data[0]\n",
    "                        if hasattr(X_val, \"shape\"):\n",
    "                            current_n_features = X_val.shape[1] if len(X_val.shape) > 1 else X_val.shape[0]\n",
    "                    elif hasattr(final_data, \"shape\"):\n",
    "                        current_n_features = final_data.shape[1] if len(final_data.shape) > 1 else final_data.shape[0]\n",
    "                    elif isinstance(final_data, dict) and \"data\" in final_data:\n",
    "                        data = final_data[\"data\"]\n",
    "                        if hasattr(data, \"shape\"):\n",
    "                            current_n_features = data.shape[1] if len(data.shape) > 1 else data.shape[0]\n",
    "            except Exception:\n",
    "                current_n_features = 0\n",
    "        \n",
    "        # Update node selected flags\n",
    "        node_flags = np.zeros(self.num_nodes, dtype=int)\n",
    "        # Mark nodes that have been selected at least once so far. We can track this by comparing pipeline_config to initial defaults.\n",
    "        for i, node in enumerate(self.pipeline_nodes):\n",
    "            # We consider a node 'selected' if its method in pipeline_config is not the initial default or if step_count > 0 and node == last_node.\n",
    "            if self.step_count > 0 and i == last_node:\n",
    "                node_flags[i] = 1\n",
    "            # (Optionally, keep track of any node changed from default too.)\n",
    "        \n",
    "        # Update method counts if tracking usage\n",
    "        method_counts = None\n",
    "        if self.include_stats:\n",
    "            total_method_options = list(self.method_index_offset.values())[-1] + len(self.methods_for_node.get(self.pipeline_nodes[-1], [])) if self.method_index_offset else 0\n",
    "            method_counts = np.zeros(total_method_options, dtype=int)\n",
    "            # Count how many times each method has been selected.\n",
    "            # We could keep a log of actions taken so far. Simpler: maintain a count dict and update each step.\n",
    "            # Here, for demonstration, we will just update for the last action (assuming this is called each step).\n",
    "            if last_node >= 0 and last_method >= 0:\n",
    "                node = self.pipeline_nodes[last_node]\n",
    "                offset = self.method_index_offset.get(node, 0)\n",
    "                method_counts[offset + last_method] += 1\n",
    "            # (Note: A more complete implementation would accumulate counts over steps.)\n",
    "        \n",
    "        # Construct observation dict\n",
    "        obs = {\n",
    "            \"step\": np.array([self.step_count], dtype=np.int32),\n",
    "            \"remaining_budget\": np.array([self.remaining_budget], dtype=np.float32),\n",
    "            \"last_node\": np.array([last_node if last_node >= 0 else 0], dtype=np.int32),\n",
    "            \"last_method\": np.array([last_method if last_method >= 0 else 0], dtype=np.int32),\n",
    "            \"last_hyperparams\": np.array(last_hyperparams, dtype=np.float32),\n",
    "            \"node_selected\": node_flags.astype(np.int8),\n",
    "            \"val_mae\": np.array([val_mae], dtype=np.float32),\n",
    "            \"val_r2\": np.array([val_r2], dtype=np.float32),\n",
    "            \"last_runtime\": np.array([runtime], dtype=np.float32),\n",
    "            \"current_n_features\": np.array([current_n_features], dtype=np.int32)\n",
    "        }\n",
    "        if self.include_stats:\n",
    "            obs[\"method_counts\"] = method_counts.astype(np.int32)\n",
    "        return obs\n",
    "    \n",
    "    def _map_hyperparams(self, node, method, hyper_vector):\n",
    "        \"\"\"\n",
    "        Map the normalized hyperparameter vector to actual hyperparameter values for the given node and method.\n",
    "        This uses predefined ranges for each method.\n",
    "        \"\"\"\n",
    "        # For simplicity, we define some example mappings based on known method hyperparameter ranges.\n",
    "        # These ranges should align with pipeline.py's expectations.\n",
    "        params = {}\n",
    "        # Node N1: Imputation methods\n",
    "        if node == 'N1':\n",
    "            if method == 'kNN':\n",
    "                # kNN: n_neighbors in [1, 15]\n",
    "                n = hyper_vector[0]\n",
    "                params['n_neighbors'] = int(1 + n * 14)  # 1 to 15\n",
    "            elif method == 'missforest':\n",
    "                # MissForest: max_iter in [5, 20]\n",
    "                n = hyper_vector[0]\n",
    "                params['max_iter'] = int(5 + n * 15)  # 5 to 20\n",
    "            # 'mean' has no hyperparameters.\n",
    "        # Node N2: Feature generation\n",
    "        if node == 'N2':\n",
    "            if method == 'cgcnn':\n",
    "                # CGCNN: embed_dim in [128, 512]\n",
    "                x = hyper_vector[0]\n",
    "                params['embed_dim'] = int(128 + x * (512 - 128))\n",
    "            # 'magpie' and 'density_symmetry' might not have tunable params in this context.\n",
    "        # Node N3: Feature selection\n",
    "        if node == 'N3':\n",
    "            if method == 'var_thresh':\n",
    "                # Variance Threshold: var_ratio in [0.0, 0.2]\n",
    "                x = hyper_vector[0]\n",
    "                params['var_ratio'] = 0.0 + x * 0.2\n",
    "            elif method == 'pfi':\n",
    "                # Permutation Feature Importance: top_k in [5, 50]\n",
    "                x = hyper_vector[0]\n",
    "                params['top_k'] = int(5 + x * 45)\n",
    "            # 'none' has no hyperparameters.\n",
    "        # Node N5: Learner\n",
    "        if node == 'N5':\n",
    "            if method == 'rf':\n",
    "                # Random Forest: n_estimators [50,800], max_depth [3,30] (31 interpreted as None)\n",
    "                x1, x2 = hyper_vector[0], hyper_vector[1]\n",
    "                params['n_estimators'] = int(50 + x1 * 750)\n",
    "                depth = int(3 + x2 * 27)\n",
    "                params['max_depth'] = None if depth >= 30 else depth  # use None if at upper bound\n",
    "            elif method == 'gbr':\n",
    "                # Gradient Boosting: learning_rate [0.01, 0.3]\n",
    "                x = hyper_vector[0]\n",
    "                params['learning_rate'] = 0.01 + x * (0.3 - 0.01)\n",
    "#         # Node N6: Hyperparameter search\n",
    "#         if node == 'N6':\n",
    "#             if method == 'random_search':\n",
    "#                 # RandomizedSearchCV: n_iter [20, 150]\n",
    "#                 x = hyper_vector[0]\n",
    "#                 params['n_iter'] = int(20 + x * 130)\n",
    "#             elif method == 'bayes_opt':\n",
    "#                 # Bayesian Optimization (TPE): trials [25, 200]\n",
    "#                 x = hyper_vector[0]\n",
    "#                 params['trials'] = int(25 + x * 175)\n",
    "        # Node N0 and others: possibly no hyperparameters needed (data fetch, scaling, etc.)\n",
    "        # 'API', 'Cache', 'standard', 'robust', 'mean' do not have tunable hyperparameters in this context.\n",
    "        return params\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"Render the current state of the environment (print the pipeline configuration and performance).\"\"\"\n",
    "        if mode != 'human':\n",
    "            return\n",
    "        print(f\"Step {self.step_count}:\")\n",
    "        print(f\"  Pipeline configuration: \")\n",
    "        for node in self.pipeline_nodes:\n",
    "            cfg = self.pipeline_config.get(node, {})\n",
    "            if not cfg:\n",
    "                continue\n",
    "            method = cfg.get(\"method\")\n",
    "            params = cfg.get(\"params\", {})\n",
    "            print(f\"    {node}: {method} {params}\")\n",
    "        print(f\"  Validation MAE: {self.last_action_metrics.get('val_mae', None) if hasattr(self, 'last_action_metrics') else 'N/A'}\")\n",
    "        print(f\"  Validation R2: {self.last_action_metrics.get('val_r2', None) if hasattr(self, 'last_action_metrics') else 'N/A'}\")\n",
    "        print(f\"  Remaining Budget: {self.remaining_budget}\")\n",
    "    \n",
    "    def get_action_space(self):\n",
    "        \"\"\"Return the action space of the environment.\"\"\"\n",
    "        return self.action_space\n",
    "    \n",
    "    def get_observation_space(self):\n",
    "        \"\"\"Return the observation space of the environment.\"\"\"\n",
    "        return self.observation_space\n",
    "    \n",
    "    def get_pipeline_config(self):\n",
    "        \"\"\"Get the current pipeline configuration.\"\"\"\n",
    "        return self.pipeline_config\n",
    "\n",
    "# End of env.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ab411",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70626e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'df_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ee797b829b96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 1. 创建环境（默认配置，严格匹配 pipeline.py）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipelineEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"环境初始化成功！\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'df_train'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fbeb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
